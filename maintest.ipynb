{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.distributions import Normal, Laplace, Independent, Bernoulli, Gamma, Uniform, Beta\n",
    "from torch.distributions.kl import kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder_layers, decoder_layers, p_z, q_z, loss_dist):\n",
    "        super(VAE, self).__init__()\n",
    "        #self.distribution1 = dist1\n",
    "        self.encoder = nn.Sequential(*encoder_layers)\n",
    "        self.decoder = nn.Sequential(*decoder_layers)\n",
    "        self.p_z = p_z\n",
    "        self.q_z = q_z\n",
    "        self.loss_dist = loss_dist\n",
    "        \n",
    "    def encode(self, x):\n",
    "        out = self.encoder(x)\n",
    "        length_out = len(out[0]) // 2\n",
    "        return out[:,:length_out], out[:,length_out:]\n",
    "\n",
    "    def reparameterize(self, q_z_given_x):\n",
    "        return q_z_given_x.rsample()\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,784)\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        \n",
    "        q_z_given_x = self.q_z(mu, logvar) # for KL divergence\n",
    "        q_z_given_x = Independent(q_z_given_x, 1)\n",
    "        \n",
    "        z = self.reparameterize(q_z_given_x)\n",
    "        x_hat = self.decode(z)\n",
    "\n",
    "        p_x_given_z = self.loss_dist(x_hat) # loss function/ distribution\n",
    "        p_x_given_z = Independent(p_x_given_z, 1)\n",
    "        loss = self.loss_function(x_hat, x, q_z_given_x, p_x_given_z, z)\n",
    "        return x_hat, loss\n",
    "    \n",
    "    def loss_function(self, x_hat, x,q_z_given_x, p_x_given_z, z):\n",
    "        BCE = torch.sum(-p_x_given_z.log_prob(x))\n",
    "        #KLD = q_z_given_x.log_prob(z) - self.p_z.log_prob(z)\n",
    "        #print(KLD)\n",
    "        KLD = kl_divergence(q_z_given_x.base_dist, self.p_z.base_dist) # vervangen en werkend krijgen \n",
    "        KLD = torch.sum(KLD.sum(len(p_z.event_shape)-1))\n",
    "        return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_dist(mu, var):\n",
    "    return Normal(loc=mu, scale=var)\n",
    "\n",
    "def laplace_dist(mu, var):\n",
    "    return Laplace(loc=mu, scale=var)\n",
    "\n",
    "def gamma_dist(mu, var):\n",
    "    return Gamma(mu, var)\n",
    "\n",
    "def beta_dist(mu, var):\n",
    "    return Beta(mu, var)\n",
    "\n",
    "def bernoulli_loss(x_hat):\n",
    "    return Bernoulli(x_hat)\n",
    "\n",
    "def laplace_loss(x_hat):\n",
    "    return Laplace(loc=x_hat, scale=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data\n",
    "        optimizer.zero_grad()\n",
    "        x_hat, loss = model(data)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data\n",
    "            x_hat, loss = model(data)\n",
    "            test_loss += loss.item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      x_hat.view(128, 1, 28, 28)[:n]])\n",
    "                #save_image(comparison.cpu(),\n",
    "                #         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size):\n",
    "    train_data = datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.ToTensor())\n",
    "    train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                               batch_size=batch_size, shuffle=True, **{})\n",
    "\n",
    "    test_data = datasets.MNIST('../data', train=False,\n",
    "                       transform=transforms.ToTensor())\n",
    "    test_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=batch_size, shuffle=True, **{})\n",
    "    return train_data, train_loader, test_data, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 545.146851\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 194.343201\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 190.309143\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 194.507446\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 181.938492\n",
      "====> Epoch: 1 Average loss: 203.9989\n",
      "====> Test set loss: 181.8062\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 181.836502\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 182.988800\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 165.737961\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 182.804520\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 174.593811\n",
      "====> Epoch: 2 Average loss: 177.9532\n",
      "====> Test set loss: 175.0792\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 178.036240\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 176.045242\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 169.152588\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 173.260712\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 173.261414\n",
      "====> Epoch: 3 Average loss: 172.3800\n",
      "====> Test set loss: 170.0214\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 169.580307\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 170.600723\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 174.052826\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 171.547333\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 166.997604\n",
      "====> Epoch: 4 Average loss: 168.2596\n",
      "====> Test set loss: 166.7758\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 163.175018\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 172.670441\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 163.447922\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 166.591721\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 159.114136\n",
      "====> Epoch: 5 Average loss: 165.5629\n",
      "====> Test set loss: 164.3729\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 162.206146\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 167.972641\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 169.878403\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 159.786652\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 155.382309\n",
      "====> Epoch: 6 Average loss: 163.6044\n",
      "====> Test set loss: 162.6496\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 157.505188\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 168.230743\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 156.745941\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 165.252823\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 163.384354\n",
      "====> Epoch: 7 Average loss: 162.0489\n",
      "====> Test set loss: 161.2689\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 154.527435\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 166.447006\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 157.074677\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 159.874603\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 157.564545\n",
      "====> Epoch: 8 Average loss: 160.6961\n",
      "====> Test set loss: 159.9989\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 157.330978\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 163.783539\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 164.687958\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 164.212540\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 159.128830\n",
      "====> Epoch: 9 Average loss: 159.4563\n",
      "====> Test set loss: 158.7444\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 157.688385\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 158.876068\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 166.201019\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 154.441254\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 154.370193\n",
      "====> Epoch: 10 Average loss: 158.2814\n",
      "====> Test set loss: 157.7623\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 157.732758\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 159.479492\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 162.693008\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 157.144775\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 160.253815\n",
      "====> Epoch: 11 Average loss: 157.2848\n",
      "====> Test set loss: 156.7183\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 159.536636\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 155.039536\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 155.247284\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 156.034973\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 156.158691\n",
      "====> Epoch: 12 Average loss: 156.3771\n",
      "====> Test set loss: 155.7267\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 158.239487\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 155.197479\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 156.074890\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 151.486389\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 149.153107\n",
      "====> Epoch: 13 Average loss: 155.4926\n",
      "====> Test set loss: 154.8453\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 159.392563\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 165.181168\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 146.421951\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 147.231659\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 155.327179\n",
      "====> Epoch: 14 Average loss: 154.6919\n",
      "====> Test set loss: 154.3225\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 157.417648\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 148.658508\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 157.035339\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 153.148117\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 150.252243\n",
      "====> Epoch: 15 Average loss: 153.9425\n",
      "====> Test set loss: 153.5293\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 150.284317\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 152.532379\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 156.416885\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 146.757690\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 157.698959\n",
      "====> Epoch: 16 Average loss: 153.2583\n",
      "====> Test set loss: 152.9017\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 160.422302\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 164.462769\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 155.421631\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 154.273148\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 148.718704\n",
      "====> Epoch: 17 Average loss: 152.5884\n",
      "====> Test set loss: 152.4895\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 154.168060\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 150.992859\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 153.403656\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 155.938110\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 150.654602\n",
      "====> Epoch: 18 Average loss: 152.0475\n",
      "====> Test set loss: 151.6928\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 150.426727\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 149.234787\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 152.367752\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 155.249359\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 155.064499\n",
      "====> Epoch: 19 Average loss: 151.5501\n",
      "====> Test set loss: 151.1469\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 152.794159\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 157.131104\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 155.067200\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 149.989807\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 154.073318\n",
      "====> Epoch: 20 Average loss: 151.0963\n",
      "====> Test set loss: 150.7236\n"
     ]
    }
   ],
   "source": [
    "x_dim = 784\n",
    "z_dim = 2\n",
    "\n",
    "encoder_layers = [\n",
    "    nn.Linear(x_dim, 400),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(400, 40),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(40, z_dim*2),\n",
    "    nn.Softplus()\n",
    "    ]\n",
    "\n",
    "decoder_layers = [\n",
    "    nn.Linear(z_dim, 40),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(40, 400),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(400, x_dim),\n",
    "    nn.Sigmoid()\n",
    "    ]\n",
    "\n",
    "lr = 1e-3\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "# prior\n",
    "#p_z = Normal(loc=torch.zeros(1,z_dim), scale=1)\n",
    "p_z = Beta(torch.tensor([0.3, 0.3]), torch.tensor([0.3, 0.3]))\n",
    "p_z = Independent(p_z,1)\n",
    "# target distribution\n",
    "q_z = beta_dist\n",
    "\n",
    "# loss function\n",
    "loss_dist = bernoulli_loss\n",
    "\n",
    "train_data, train_loader, test_data, test_loader = load_data(batch_size)\n",
    "model = VAE(encoder_layers, decoder_layers, p_z, q_z, loss_dist)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "if __name__ == \"__main__\":\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "        #with torch.no_grad():\n",
    "        #    sample = torch.randn(64, 20)\n",
    "        #    sample = model.decode(sample)\n",
    "        #    save_image(sample.view(64, 1, 28, 28),\n",
    "        #               'results/sample_' + str(epoch) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/sample_norm2laplace20.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b5019c50ded8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'results/sample_norm2laplace'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/medical_vae/lib/python3.6/site-packages/torchvision/utils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(tensor, filename, nrow, padding, normalize, range, scale_each, pad_value)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mndarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/medical_vae/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1989\u001b[0m                 \u001b[0;31m# Open also for reading (\"+\"), because TIFF save_all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1990\u001b[0m                 \u001b[0;31m# writer needs to go back and edit the written data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1991\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/sample_norm2laplace20.png'"
     ]
    }
   ],
   "source": [
    "xv = np.arange(0, 4, .05)\n",
    "yv = np.arange(0, 4, .05)\n",
    "sample = np.zeros([len(yv)*len(xv), 2])\n",
    "counter = 0\n",
    "for i in xv:\n",
    "    for j in yv:\n",
    "        sample[counter] = [i, j]\n",
    "        counter += 1\n",
    "\n",
    "images = model.decode(torch.tensor(sample, dtype=torch.float)).detach().numpy()\n",
    "image = np.zeros([len(xv)*28, len(yv)*28])\n",
    "counter = 0\n",
    "for i in range(len(xv)):\n",
    "    for j in range(len(yv)):\n",
    "        image[i*28:i*28+28,j*28:j*28+28] = images[counter].reshape((28,28))\n",
    "        counter += 1\n",
    "\n",
    "save_image(torch.tensor(image),'results/sample_norm2laplace' + str(epoch) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 784\n",
    "z_dim = 2\n",
    "encoder_layers = [\n",
    "    nn.Linear(x_dim, 128),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(128, z_dim*2)\n",
    "    ]\n",
    "\n",
    "decoder_layers = [\n",
    "    nn.Linear(2, 128),\n",
    "    nn.ReLU(True),\n",
    "    nn.Linear(128, x_dim)\n",
    "    ]\n",
    "print(encoder_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.6.8"
=======
   "version": "3.6.5"
>>>>>>> 821524fc90e95d8c9874faa613d0450f23984836
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
